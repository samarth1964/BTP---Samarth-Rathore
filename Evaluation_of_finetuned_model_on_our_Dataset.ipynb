{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXEOC_vcAxzK"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers evaluate seqeval pandas\n",
        "\n",
        "import json, os, glob, csv\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "\n",
        "# ---------- SETTINGS ----------\n",
        "base_dir = \".\"\n",
        "pattern = os.path.join(base_dir, \"projected_hi_*_ner.jsonl\")\n",
        "files = sorted(glob.glob(pattern))\n",
        "if not files:\n",
        "    raise SystemExit(f\"No files matched {pattern}\")\n",
        "\n",
        "model_name = \"Davlan/xlm-roberta-base-wikiann-ner\"\n",
        "\n",
        "# ---------- load model ----------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "id2label = model.config.id2label\n",
        "\n",
        "print(\"Model:\", model_name, \"Device:\", device)\n",
        "print(\"Files:\", files)\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def load_jsonl_examples(path: str, token_field=\"target_tokens\", tag_field=\"target_tags\"):\n",
        "    exs = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line=line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            obj = json.loads(line)\n",
        "            toks = obj.get(token_field) or obj.get(\"target_tokens\") or obj.get(\"tokens\")\n",
        "            tags = obj.get(tag_field) or obj.get(\"target_tags\") or obj.get(\"tags\")\n",
        "            if toks is None or tags is None:\n",
        "                continue\n",
        "            if len(toks) != len(tags):\n",
        "                continue\n",
        "            exs.append({\"tokens\": toks, \"tags\": tags})\n",
        "    return exs\n",
        "\n",
        "def flat_to_bio(flat_tags: List[str]) -> List[str]:\n",
        "    bio=[]\n",
        "    prev=\"O\"\n",
        "    for t in flat_tags:\n",
        "        t = \"O\" if (t is None) else str(t)\n",
        "        if t.upper()==\"O\":\n",
        "            bio.append(\"O\"); prev=\"O\"\n",
        "        else:\n",
        "            if prev==t:\n",
        "                bio.append(\"I-\"+t)\n",
        "            else:\n",
        "                bio.append(\"B-\"+t)\n",
        "            prev=t\n",
        "    return bio\n",
        "\n",
        "def bio_to_flat(bio_tag: str) -> str:\n",
        "    if bio_tag is None: return \"O\"\n",
        "    if bio_tag==\"O\": return \"O\"\n",
        "    if bio_tag.startswith(\"B-\") or bio_tag.startswith(\"I-\"):\n",
        "        return bio_tag.split(\"-\",1)[1]\n",
        "    return bio_tag\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_for_tokens(tokens: List[str]) -> List[str]:\n",
        "    enc = tokenizer(tokens, is_split_into_words=True, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    enc = {k:v.to(device) for k,v in enc.items()}\n",
        "    outputs = model(**enc)\n",
        "    logits = outputs.logits.detach().cpu().numpy()[0]  # (seq_len, num_labels)\n",
        "    pred_ids = np.argmax(logits, axis=-1)\n",
        "    # obtain word_ids from non-tensor encoding\n",
        "    enc2 = tokenizer(tokens, is_split_into_words=True, truncation=True)\n",
        "    word_ids = enc2.word_ids()\n",
        "    preds_per_word=[]\n",
        "    last_word=None\n",
        "    for idx, w in enumerate(word_ids):\n",
        "        if w is None:\n",
        "            continue\n",
        "        if w != last_word:\n",
        "            label_id = int(pred_ids[idx])\n",
        "            model_label = id2label[label_id]\n",
        "            preds_per_word.append(bio_to_flat(model_label))\n",
        "        last_word = w\n",
        "    # align length\n",
        "    if len(preds_per_word) != len(tokens):\n",
        "        if len(preds_per_word) > len(tokens):\n",
        "            preds_per_word = preds_per_word[:len(tokens)]\n",
        "        else:\n",
        "            preds_per_word += [\"O\"] * (len(tokens) - len(preds_per_word))\n",
        "    return preds_per_word\n",
        "\n",
        "# metrics helpers\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "def compute_token_metrics(gold_flat, pred_flat):\n",
        "    p_mac, r_mac, f1_mac, _ = precision_recall_fscore_support(gold_flat, pred_flat, average=\"macro\", zero_division=0)\n",
        "    p_mi, r_mi, f1_mi, _ = precision_recall_fscore_support(gold_flat, pred_flat, average=\"micro\", zero_division=0)\n",
        "    acc = accuracy_score(gold_flat, pred_flat)\n",
        "    return {\"precision_macro\": p_mac, \"recall_macro\": r_mac, \"f1_macro\": f1_mac,\n",
        "            \"precision_micro\": p_mi, \"recall_micro\": r_mi, \"f1_micro\": f1_mi,\n",
        "            \"accuracy\": acc}\n",
        "\n",
        "def compute_entity_metrics(gold_bios, pred_bios):\n",
        "    res = seqeval.compute(predictions=pred_bios, references=gold_bios)\n",
        "    overall = {k: res[k] for k in [\"overall_precision\",\"overall_recall\",\"overall_f1\",\"overall_accuracy\"] if k in res}\n",
        "    return overall, res\n",
        "\n",
        "# ---------- per-file evaluation ----------\n",
        "rows = []\n",
        "aggregate_gold=[]\n",
        "aggregate_pred=[]\n",
        "\n",
        "for fpath in files:\n",
        "    examples = load_jsonl_examples(fpath)\n",
        "    if not examples:\n",
        "        print(\"Skipping\", fpath, \"- no examples\")\n",
        "        continue\n",
        "\n",
        "    gold_flat_all=[]\n",
        "    pred_flat_all=[]\n",
        "    gold_bio_seqs=[]\n",
        "    pred_bio_seqs=[]\n",
        "\n",
        "    for ex in examples:\n",
        "        toks = ex[\"tokens\"]\n",
        "        gold_tags = ex[\"tags\"]\n",
        "        # normalize gold\n",
        "        if any(isinstance(t,str) and (t.startswith(\"B-\") or t.startswith(\"I-\")) for t in gold_tags):\n",
        "            gold_bio = [str(t) for t in gold_tags]\n",
        "            gold_flat = [bio_to_flat(t) for t in gold_bio]\n",
        "        else:\n",
        "            gold_flat = [str(t) for t in gold_tags]\n",
        "            gold_bio = flat_to_bio(gold_flat)\n",
        "\n",
        "        preds_flat = predict_for_tokens(toks)\n",
        "        preds_bio = flat_to_bio(preds_flat)\n",
        "\n",
        "        gold_flat_all.extend(gold_flat)\n",
        "        pred_flat_all.extend(preds_flat)\n",
        "        gold_bio_seqs.append(gold_bio)\n",
        "        pred_bio_seqs.append(preds_bio)\n",
        "\n",
        "    token_metrics = compute_token_metrics(gold_flat_all, pred_flat_all)\n",
        "    entity_overall, entity_full = compute_entity_metrics(gold_bio_seqs, pred_bio_seqs)\n",
        "\n",
        "    lang_name = os.path.basename(fpath).replace(\"projected_hi_\",\"\").replace(\"_ner.jsonl\",\"\")\n",
        "    row = {\n",
        "        \"file\": os.path.basename(fpath),\n",
        "        \"lang\": lang_name,\n",
        "        \"n_examples\": len(examples),\n",
        "        \"n_tokens\": len(gold_flat_all),\n",
        "        # token-level\n",
        "        \"token_precision_macro\": token_metrics[\"precision_macro\"],\n",
        "        \"token_recall_macro\": token_metrics[\"recall_macro\"],\n",
        "        \"token_f1_macro\": token_metrics[\"f1_macro\"],\n",
        "        \"token_precision_micro\": token_metrics[\"precision_micro\"],\n",
        "        \"token_recall_micro\": token_metrics[\"recall_micro\"],\n",
        "        \"token_f1_micro\": token_metrics[\"f1_micro\"],\n",
        "        \"token_accuracy\": token_metrics[\"accuracy\"],\n",
        "        # entity-level (seqeval overall)\n",
        "        \"entity_precision\": entity_overall.get(\"overall_precision\", None),\n",
        "        \"entity_recall\": entity_overall.get(\"overall_recall\", None),\n",
        "        \"entity_f1\": entity_overall.get(\"overall_f1\", None),\n",
        "        \"entity_accuracy\": entity_overall.get(\"overall_accuracy\", None),\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "    aggregate_gold.extend(gold_flat_all)\n",
        "    aggregate_pred.extend(pred_flat_all)\n",
        "\n",
        "    # quick print per language\n",
        "    print(f\"\\n=== {lang_name} === examples: {len(examples)} tokens: {len(gold_flat_all)}\")\n",
        "    print(f\"Token F1 (micro): {token_metrics['f1_micro']:.4f}  Precision (micro): {token_metrics['precision_micro']:.4f}  Recall (micro): {token_metrics['recall_micro']:.4f}  Acc: {token_metrics['accuracy']:.4f}\")\n",
        "    print(f\"Entity F1: {entity_overall.get('overall_f1', 'N/A')}  P: {entity_overall.get('overall_precision', 'N/A')}  R: {entity_overall.get('overall_recall', 'N/A')}\")\n",
        "\n",
        "# ---------- aggregated metrics ----------\n",
        "if aggregate_gold:\n",
        "    agg_token = compute_token_metrics(aggregate_gold, aggregate_pred)\n",
        "    print(\"\\n=== AGGREGATE ACROSS ALL LANGUAGES ===\")\n",
        "    print(f\"Total tokens: {len(aggregate_gold)}\")\n",
        "    print(f\"Token F1 (micro): {agg_token['f1_micro']:.4f}  P: {agg_token['precision_micro']:.4f}  R: {agg_token['recall_micro']:.4f}  Acc: {agg_token['accuracy']:.4f}\")\n",
        "\n",
        "# ---------- save results ----------\n",
        "df = pd.DataFrame(rows)\n",
        "csv_out = \"per_file_metrics.csv\"\n",
        "df.to_csv(csv_out, index=False)\n",
        "with open(\"aggregate_metrics.json\",\"w\",encoding=\"utf-8\") as fo:\n",
        "    json.dump({\"aggregate_token_metrics\": agg_token if aggregate_gold else None, \"files\": rows}, fo, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\nPer-file metrics written to {csv_out}\")\n",
        "print(\"Aggregate saved to aggregate_metrics.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_rnweuTEzZG"
      },
      "source": [
        "TEMPORAL ENTITY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iIVLwEBkxuEe"
      },
      "outputs": [],
      "source": [
        "# Recursively read all xmls in HindiTimeBank subfolders, train (TIMEX-only) with oversampling, evaluate.\n",
        "!pip install -q transformers datasets evaluate seqeval\n",
        "\n",
        "import os, glob, re, xml.etree.ElementTree as ET, json\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import torch\n",
        "import evaluate\n",
        "from datasets import Dataset as HFDataset, DatasetDict as HFDatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForTokenClassification,\n",
        "    DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
        ")\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "# ---------------- CONFIG - change these ----------------\n",
        "BASE_DIR = \"/content/HindiTimeBank\"   # your main folder containing subfolders with XMLs\n",
        "MODEL_NAME = \"Davlan/xlm-roberta-base-wikiann-ner\"\n",
        "OUTPUT_DIR = \"./timebank_recursive_timex\"\n",
        "ID_START, ID_END = 0, 99999   # we'll auto-collect all files; use range if you want to filter numeric IDs\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "TIMEX_ONLY = True                  # collapse everything non-TIMEX -> O\n",
        "TIMEX_OVERSAMPLE_FACTOR = 3        # duplicate docs with TIMEX in train\n",
        "DO_TRAIN = True                    # set False to skip training (will still evaluate with base model)\n",
        "EPOCHS = 6\n",
        "BATCH_SIZE = 4                     # lower if GPU memory limited\n",
        "LR = 1e-5\n",
        "# -----------------------------------------------------\n",
        "\n",
        "# === find xml files recursively ===\n",
        "xml_paths = sorted(glob.glob(os.path.join(BASE_DIR, \"**\", \"*.xml\"), recursive=True))\n",
        "if not xml_paths:\n",
        "    raise SystemExit(f\"No XML files found under {BASE_DIR}. Make sure folder is uploaded.\")\n",
        "print(\"Found XML files (recursively):\", len(xml_paths))\n",
        "\n",
        "def extract_id_from_path(path):\n",
        "    # return first numeric sequence in filename if you want to filter; else return full stem\n",
        "    m = re.search(r\"(\\d+)\", Path(path).stem)\n",
        "    return int(m.group(1)) if m else Path(path).stem\n",
        "\n",
        "# === parse TimeBank-style XML (token ids -> tokens + BIO tags) ===\n",
        "def parse_timebank_xml(path):\n",
        "    tree = ET.parse(path); root = tree.getroot()\n",
        "    tokens = []; id2idx = {}\n",
        "    for t in root.findall(\"token\"):\n",
        "        tid = t.attrib.get(\"id\")\n",
        "        text = (t.text or \"\").strip()\n",
        "        tokens.append(text)\n",
        "        id2idx[tid] = len(tokens)-1\n",
        "    labels = [\"O\"] * len(tokens)\n",
        "    def assign(tok_ids, prefix):\n",
        "        if not tok_ids: return\n",
        "        ids = [s.strip() for s in tok_ids.split(\",\") if s.strip()]\n",
        "        positions = [id2idx.get(i) for i in ids if i in id2idx]\n",
        "        if not positions: return\n",
        "        positions = sorted(positions)\n",
        "        labels[positions[0]] = \"B-\" + prefix\n",
        "        for p in positions[1:]:\n",
        "            labels[p] = \"I-\" + prefix\n",
        "    for ev in root.findall(\"EVENT\"):\n",
        "        tok_attr = ev.attrib.get(\"tokens\") or ev.attrib.get(\"token\")\n",
        "        cls = ev.attrib.get(\"class\"); prefix = \"EVENT\" if not cls else f\"EVENT_{cls}\"\n",
        "        assign(tok_attr, prefix)\n",
        "    for st in root.findall(\"STATE\"):\n",
        "        tok_attr = st.attrib.get(\"tokens\") or st.attrib.get(\"token\")\n",
        "        cls = st.attrib.get(\"class\"); prefix = \"STATE\" if not cls else f\"STATE_{cls}\"\n",
        "        assign(tok_attr, prefix)\n",
        "    for tm in root.findall(\"TIMEX\"):\n",
        "        tok_attr = tm.attrib.get(\"tokens\") or tm.attrib.get(\"token\")\n",
        "        cls = tm.attrib.get(\"class\"); prefix = \"TIMEX\" if not cls else f\"TIMEX_{cls}\"\n",
        "        assign(tok_attr, prefix)\n",
        "    return {\"tokens\": tokens, \"tags\": labels, \"doc\": os.path.relpath(path, BASE_DIR)}\n",
        "\n",
        "# parse all xmls\n",
        "examples_raw = [parse_timebank_xml(p) for p in xml_paths]\n",
        "print(\"Parsed documents:\", len(examples_raw))\n",
        "\n",
        "# optionally collapse to TIMEX-only labels\n",
        "def collapse_to_timex_only(example):\n",
        "    new_tags = []\n",
        "    for t in example[\"tags\"]:\n",
        "        if t.startswith(\"B-TIMEX\"): new_tags.append(\"B-TIMEX\")\n",
        "        elif t.startswith(\"I-TIMEX\"): new_tags.append(\"I-TIMEX\")\n",
        "        else: new_tags.append(\"O\")\n",
        "    return {\"tokens\": example[\"tokens\"], \"tags\": new_tags, \"doc\": example[\"doc\"]}\n",
        "\n",
        "if TIMEX_ONLY:\n",
        "    examples = [collapse_to_timex_only(e) for e in examples_raw]\n",
        "    print(\"Collapsed labels to TIMEX-only.\")\n",
        "else:\n",
        "    examples = examples_raw\n",
        "\n",
        "# build stratification label (presence of TIMEX)\n",
        "has_timex = [int(any(t.startswith(\"B-TIMEX\") or t.startswith(\"I-TIMEX\") for t in ex[\"tags\"])) for ex in examples]\n",
        "print(\"Documents containing TIMEX:\", sum(has_timex), \"/\", len(has_timex))\n",
        "\n",
        "# do stratified split: train(80)/val(10)/test(10) by document\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=RANDOM_SEED)\n",
        "train_val_idx, test_idx = next(sss.split(np.arange(len(examples)), has_timex))\n",
        "train_val = [examples[i] for i in train_val_idx]\n",
        "test_docs = [examples[i] for i in test_idx]\n",
        "# split train_val -> train/val ~ 0.9/0.1 of original (so val ~0.1 total)\n",
        "tv_has = [has_timex[i] for i in train_val_idx]\n",
        "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.1111, random_state=RANDOM_SEED)\n",
        "train_idx_rel, val_idx_rel = next(sss2.split(np.arange(len(train_val)), tv_has))\n",
        "train_docs = [train_val[i] for i in train_idx_rel]\n",
        "val_docs = [train_val[i] for i in val_idx_rel]\n",
        "\n",
        "print(\"Split sizes -> train:\", len(train_docs), \"val:\", len(val_docs), \"test:\", len(test_docs))\n",
        "\n",
        "# Oversample TIMEX docs in training\n",
        "def contains_timex(ex): return any(t.startswith(\"B-TIMEX\") or t.startswith(\"I-TIMEX\") for t in ex[\"tags\"])\n",
        "oversampled_train = []\n",
        "for ex in train_docs:\n",
        "    if contains_timex(ex):\n",
        "        for _ in range(TIMEX_OVERSAMPLE_FACTOR):\n",
        "            oversampled_train.append({\"tokens\": ex[\"tokens\"], \"tags\": ex[\"tags\"], \"doc\": ex[\"doc\"]})\n",
        "    else:\n",
        "        oversampled_train.append(ex)\n",
        "print(\"Train size before:\", len(train_docs), \"after oversample:\", len(oversampled_train))\n",
        "\n",
        "# create HF DatasetDict\n",
        "ds = HFDatasetDict({\n",
        "    \"train\": HFDataset.from_list(oversampled_train),\n",
        "    \"validation\": HFDataset.from_list(val_docs),\n",
        "    \"test\": HFDataset.from_list(test_docs)\n",
        "})\n",
        "\n",
        "# label set (TIMEX-only or full set)\n",
        "labels = sorted({lab for ex in examples for lab in ex[\"tags\"]})\n",
        "# ensure O last\n",
        "if \"O\" in labels:\n",
        "    labels = [l for l in labels if l != \"O\"] + [\"O\"]\n",
        "label2id = {lab:i for i,lab in enumerate(labels)}\n",
        "id2label = {i:lab for lab,i in label2id.items()}\n",
        "print(\"Labels:\", labels)\n",
        "\n",
        "# tokenizer + alignment\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "\n",
        "def tokenize_and_align_labels(batch):\n",
        "    tokenized = tokenizer(batch[\"tokens\"], is_split_into_words=True, truncation=True)\n",
        "    all_labels=[]\n",
        "    for i,labs in enumerate(batch[\"tags\"]):\n",
        "        word_ids = tokenized.word_ids(batch_index=i)\n",
        "        label_ids=[]\n",
        "        for w in word_ids:\n",
        "            if w is None:\n",
        "                label_ids.append(-100)\n",
        "            else:\n",
        "                label_ids.append(label2id[labs[w]])\n",
        "        all_labels.append(label_ids)\n",
        "    tokenized[\"labels\"] = all_labels\n",
        "    return tokenized\n",
        "\n",
        "for split in [\"train\",\"validation\",\"test\"]:\n",
        "    if len(ds[split])>0:\n",
        "        ds[split] = ds[split].map(tokenize_and_align_labels, batched=True, remove_columns=[\"tokens\",\"tags\",\"doc\"])\n",
        "print(\"Tokenized sizes:\", {k: len(ds[k]) for k in ds})\n",
        "\n",
        "# load model (ignore mismatch so classifier re-init to new num_labels)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, num_labels=len(labels), ignore_mismatched_sizes=True)\n",
        "model.config.id2label = id2label\n",
        "model.config.label2id = label2id\n",
        "model.to(device)\n",
        "\n",
        "# metrics for Trainer\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, label_ids = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    true_preds=[]; true_labels=[]\n",
        "    for pred_row, lab_row in zip(preds, label_ids):\n",
        "        pseq=[]; lseq=[]\n",
        "        for p,l in zip(pred_row, lab_row):\n",
        "            if l == -100:\n",
        "                continue\n",
        "            pseq.append(model.config.id2label[int(p)])\n",
        "            lseq.append(model.config.id2label[int(l)])\n",
        "        true_preds.append(pseq); true_labels.append(lseq)\n",
        "    res = seqeval.compute(predictions=true_preds, references=true_labels) if len(true_labels)>0 else {}\n",
        "    # token-level flat (collapse BIO to TIMEX vs O)\n",
        "    def bio_to_flat(seq): return [\"O\" if x==\"O\" else x.split(\"-\",1)[1] for x in seq]\n",
        "    flat_gold = [g for seq in true_labels for g in bio_to_flat(seq)]\n",
        "    flat_pred = [p for seq in true_preds for p in bio_to_flat(seq)]\n",
        "    if flat_gold:\n",
        "        p_micro, r_micro, f1_micro, _ = precision_recall_fscore_support(flat_gold, flat_pred, average=\"micro\", zero_division=0)\n",
        "    else:\n",
        "        p_micro=r_micro=f1_micro=0.0\n",
        "    return {\"entity_overall_f1\": res.get(\"overall_f1\", 0.0), \"token_f1_micro\": f1_micro}\n",
        "\n",
        "# train\n",
        "if DO_TRAIN:\n",
        "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        learning_rate=LR,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=max(1, BATCH_SIZE*2),\n",
        "        num_train_epochs=EPOCHS,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=20,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"entity_overall_f1\",\n",
        "        greater_is_better=True,\n",
        "        seed=RANDOM_SEED\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model=model, args=training_args,\n",
        "        train_dataset=ds[\"train\"],\n",
        "        eval_dataset=ds[\"validation\"] if len(ds[\"validation\"])>0 else None,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "    trainer.train()\n",
        "    trainer.save_model(OUTPUT_DIR)\n",
        "    tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "    print(\"Saved model to\", OUTPUT_DIR)\n",
        "else:\n",
        "    print(\"DO_TRAIN is False â€” skipping training (model is base checkpoint).\")\n",
        "\n",
        "# evaluate on test docs and save predictions\n",
        "model.eval()\n",
        "all_gold_flat = []; all_pred_flat = []; gold_bio_seqs = []; pred_bio_seqs = []; out_preds=[]\n",
        "for orig in test_docs:\n",
        "    toks = orig[\"tokens\"]; gold_bio = orig[\"tags\"]\n",
        "    enc = tokenizer(toks, is_split_into_words=True, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    enc = {k:v.to(device) for k,v in enc.items()}\n",
        "    with torch.no_grad():\n",
        "        out = model(**enc)\n",
        "        logits = out.logits.cpu().numpy()[0]\n",
        "        pred_ids = np.argmax(logits, axis=-1)\n",
        "    enc2 = tokenizer(toks, is_split_into_words=True, truncation=True)\n",
        "    word_ids = enc2.word_ids()\n",
        "    preds = []; last=None\n",
        "    for idx,w in enumerate(word_ids):\n",
        "        if w is None: continue\n",
        "        if w != last:\n",
        "            preds.append(model.config.id2label.get(int(pred_ids[idx]), \"O\"))\n",
        "        last = w\n",
        "    # safety align\n",
        "    if len(preds) != len(toks):\n",
        "        if len(preds) > len(toks): preds = preds[:len(toks)]\n",
        "        else: preds += [\"O\"] * (len(toks)-len(preds))\n",
        "    pred_bio = preds\n",
        "    # flat TIMEX vs O\n",
        "    def bio_flat_to_tag(b): return \"O\" if b==\"O\" else b.split(\"-\",1)[1]\n",
        "    pred_flat = [bio_flat_to_tag(x) for x in pred_bio]\n",
        "    gold_flat = [bio_flat_to_tag(x) for x in gold_bio]\n",
        "    all_gold_flat.extend(gold_flat); all_pred_flat.extend(pred_flat)\n",
        "    gold_bio_seqs.append(gold_bio); pred_bio_seqs.append(pred_bio)\n",
        "    out_preds.append({\"doc\": orig[\"doc\"], \"tokens\": toks, \"gold_bio\": gold_bio, \"pred_bio\": pred_bio})\n",
        "\n",
        "with open(\"test_predictions.jsonl\",\"w\",encoding=\"utf-8\") as fo:\n",
        "    for r in out_preds: fo.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "print(\"Wrote test_predictions.jsonl\")\n",
        "\n",
        "# print counters + one missed example\n",
        "gold_counts = Counter([x for seq in gold_bio_seqs for x in seq])\n",
        "pred_counts = Counter([x for seq in pred_bio_seqs for x in seq])\n",
        "print(\"\\nGold BIO counts:\", gold_counts)\n",
        "print(\"Pred BIO counts:\", pred_counts)\n",
        "print(\"Pred B-TIMEX:\", pred_counts.get(\"B-TIMEX\",0), \"I-TIMEX:\", pred_counts.get(\"I-TIMEX\",0))\n",
        "\n",
        "# token-level metrics\n",
        "if all_gold_flat:\n",
        "    p_macro, r_macro, f1_macro, _ = precision_recall_fscore_support(all_gold_flat, all_pred_flat, average=\"macro\", zero_division=0)\n",
        "    p_micro, r_micro, f1_micro, _ = precision_recall_fscore_support(all_gold_flat, all_pred_flat, average=\"micro\", zero_division=0)\n",
        "    acc = accuracy_score(all_gold_flat, all_pred_flat)\n",
        "else:\n",
        "    p_macro=r_macro=f1_macro=p_micro=r_micro=f1_micro=acc=0.0\n",
        "\n",
        "print(\"\\nTOKEN-LEVEL (flat labels):\")\n",
        "print(f\"Macro   P: {p_macro:.4f}  R: {r_macro:.4f}  F1: {f1_macro:.4f}\")\n",
        "print(f\"Micro   P: {p_micro:.4f}  R: {r_micro:.4f}  F1: {f1_micro:.4f}\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "\n",
        "# entity-level\n",
        "if gold_bio_seqs:\n",
        "    ent_res = seqeval.compute(predictions=pred_bio_seqs, references=gold_bio_seqs)\n",
        "    print(\"\\nENTITY-LEVEL (seqeval) overall:\")\n",
        "    for k in (\"overall_precision\",\"overall_recall\",\"overall_f1\",\"overall_accuracy\"):\n",
        "        if k in ent_res: print(f\"{k}: {ent_res[k]}\")\n",
        "    print(\"\\nEntity breakdown:\")\n",
        "    for k,v in ent_res.items():\n",
        "        if not k.startswith(\"overall_\"):\n",
        "            print(k, \":\", v)\n",
        "else:\n",
        "    print(\"\\nNo entity sequences present for evaluation.\")\n",
        "\n",
        "# print first missed-TIMEX doc\n",
        "def has_timex(seq): return any(x.startswith(\"B-TIMEX\") or x.startswith(\"I-TIMEX\") for x in seq)\n",
        "for r in out_preds:\n",
        "    if has_timex(r[\"gold_bio\"]) and not has_timex(r[\"pred_bio\"]):\n",
        "        print(\"\\n--- Missed TIMEX doc:\", r[\"doc\"])\n",
        "        for tok,g,p in zip(r[\"tokens\"], r[\"gold_bio\"], r[\"pred_bio\"]):\n",
        "            print(f\"{tok:20s} GOLD={g:10s} PRED={p:10s}\")\n",
        "        break\n",
        "else:\n",
        "    print(\"\\nNo missed-TIMEX docs found (every gold-TIMEX doc has at least one predicted TIMEX token).\")\n",
        "\n",
        "print(\"\\nDone.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgLVWEq31jD8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}